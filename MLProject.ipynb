{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLProject.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ntuananh/CS582_MachineLearning/blob/master/MLProject.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "qBqPsRXMZrux",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://www.youtube.com/watch?v=XOEN9W05_4A - video demo for capturing data\n",
        "\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "XaYZoluuY8eE",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Setup Enviroment & Import Data\n",
        "# Read data from Google Drive\n",
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        " \n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "#List files\n",
        "#file_list = drive.ListFile({'q': \"'11f05x7C5kbWdpTdRJVwbPgV7MOG_D6fv' in parents and trashed=false\"}).GetList()\n",
        "#for file1 in file_list:\n",
        "#  print('title: %s, id: %s' % (file1['title'], file1['id']))\n",
        "  \n",
        "# create Files and pull content to Colab\n",
        "train_N = drive.CreateFile({'id': '1qAj6Hqqoss0bAuYuVWGSoOZgmvMkZ6k2'})\n",
        "train_N.GetContentFile('train_N.csv')\n",
        "test_N = drive.CreateFile({'id': '1hv9hqdvvTMJGPPqMTsd0YS58_0nio97G'})\n",
        "test_N.GetContentFile('test_N.csv')\n",
        "\n",
        "train = drive.CreateFile({'id': '1mXbabpIXPB_57pOvam9bjKOBVnQAoeML'})\n",
        "train.GetContentFile('train.csv')\n",
        "test = drive.CreateFile({'id': '1JjEDt8q_VPWfVCN7MOexIwY1I1GtTLfC'})\n",
        "test.GetContentFile('test.csv')\n",
        "\n",
        "# read files'content into dataframe\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "train_data_N = pd.read_csv('train_N.csv')\n",
        "test_data_N = pd.read_csv('test_N.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GUgg6xmcLtBA",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Import libraries\n",
        "#import Libs\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qYninXyVB_i5",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title KDTree\n",
        "#https://en.wikipedia.org/wiki/K-d_tree\n",
        "  \n",
        "from collections import namedtuple\n",
        "from operator import itemgetter\n",
        "from pprint import pformat\n",
        "\n",
        "class Node(namedtuple('Node', 'location left_child right_child')):\n",
        "    def __repr__(self):\n",
        "        return pformat(tuple(self))\n",
        "\n",
        "def kdtree(point_list, depth=0):\n",
        "    try:\n",
        "        k = len(point_list[0]) # assumes all points have the same dimension\n",
        "    except IndexError as e: # if not point_list:\n",
        "        return None\n",
        "    # Select axis based on depth so that axis cycles through all valid values\n",
        "    axis = depth % k\n",
        " \n",
        "    # Sort point list and choose median as pivot element\n",
        "    point_list.sort(key=itemgetter(axis))\n",
        "    median = len(point_list) // 2 # choose median\n",
        " \n",
        "    # Create node and construct subtrees\n",
        "    return Node(\n",
        "        location=point_list[median],\n",
        "        left_child=kdtree(point_list[:median], depth + 1),\n",
        "        right_child=kdtree(point_list[median + 1:], depth + 1)\n",
        "    )\n",
        "\n",
        "def main():\n",
        "    \"\"\"Example usage\"\"\"\n",
        "    point_list = [(2,3), (5,4), (9,6), (4,7), (8,1), (7,2)]\n",
        "    tree = kdtree(point_list)\n",
        "    print(tree)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HsLr7wYfPdS2",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title KNearestNeighbour Class\n",
        "# Custom KNN \n",
        "import time\n",
        "import collections\n",
        "\n",
        "class KNearestNeighbour:\n",
        "    def __init__(self, data: pd.DataFrame, label_column: str, data_dimension: int=-1):\n",
        "        self.label_column = label_column\n",
        "        self.labels = data.pop(label_column).tolist()\n",
        "        self.properties = data.values.tolist()\n",
        "        self.size = len(self.labels)\n",
        "        # as a rule of thumb implemented in many library, but may not yield an outstanding result compare to others\n",
        "        self.max_k = int(self.size ** 0.5)\n",
        "        self.data_dimension = data_dimension\n",
        "        if data_dimension > 0:\n",
        "            red_dim = self.pca(self.properties, data_dimension)\n",
        "            self.properties = red_dim[0]\n",
        "            self.mean = red_dim[1]\n",
        "            self.ev = red_dim[2]\n",
        "\n",
        "    @classmethod\n",
        "    def euclidean_distance(cls, p1: list, p2: list) -> float:\n",
        "        return sum(np.square(np.array(p1) - np.array(p2))) ** 0.5\n",
        "\n",
        "    @classmethod\n",
        "    def manhattan_distance(cls, p1: list, p2: list) -> float:\n",
        "        return sum(np.abs(np.array(p1) - np.array(p2)))\n",
        "\n",
        "    def analyze(self, test_data: list) -> list:\n",
        "        if self.data_dimension > 0:\n",
        "            test_data = np.transpose(np.dot(np.transpose(self.ev), np.transpose(np.array(test_data) - self.mean)))\n",
        "        r = []\n",
        "        for i in range(self.size):\n",
        "            r.append((KNearestNeighbour.manhattan_distance(test_data, self.properties[i]), i))\n",
        "        r.sort(key=lambda e: e[0])\n",
        "        return [self.labels[r[i][1]] for i in range(min(self.max_k, len(r)))]\n",
        "\n",
        "    @classmethod\n",
        "    def verdict(cls, nearest_neighbours: list, k: int):\n",
        "        return collections.Counter(nearest_neighbours[:min(k, len(nearest_neighbours))]).most_common(1)[0][0]\n",
        "\n",
        "    @classmethod\n",
        "    def explain(cls, nearest_neighbours: list, k: int):\n",
        "        d = dict(collections.Counter(nearest_neighbours[:min(k, len(nearest_neighbours))]).most_common())\n",
        "        return {e: d[e]/k for e in d}\n",
        "\n",
        "    @classmethod\n",
        "    def pca(cls, data, n_components):\n",
        "        mean = np.mean(data, axis=0)\n",
        "        data -= mean\n",
        "        cov_matrix = np.cov(np.transpose(data))\n",
        "\n",
        "        eigen_values, eigen_vectors = np.linalg.eig(cov_matrix)\n",
        "        indices = np.argsort(eigen_values)[::-1]\n",
        "        eigen_vectors = eigen_vectors[:, indices]\n",
        "        eigen_vectors = eigen_vectors[:, :n_components]\n",
        "        for i in range(np.shape(eigen_vectors)[1]):\n",
        "            eigen_vectors[:, i] /= np.linalg.norm(eigen_vectors[:, i])\n",
        "\n",
        "        transformed_data = np.transpose(np.dot(np.transpose(eigen_vectors), np.transpose(data)))\n",
        "        # original_data = np.transpose(np.dot(evecs, x)) + m\n",
        "        return transformed_data, mean, eigen_vectors\n",
        "\n",
        "    @classmethod\n",
        "    def test_model(cls, model, k: int, tests: pd.DataFrame, build_confusion_matrix: bool=False):\n",
        "        expected_labels = tests.pop(model.label_column)\n",
        "        tests = tests.values.tolist()\n",
        "\n",
        "        success_count = 0\n",
        "        failed_tests = []\n",
        "        total_time = 0\n",
        "\n",
        "        confusion_matrix = None\n",
        "        labels_mapping = None\n",
        "        if build_confusion_matrix:\n",
        "            labels = np.unique(np.array(knn.labels))\n",
        "            confusion_matrix = np.zeros((len(labels), len(labels)))\n",
        "            labels_mapping = {l: i for i, l in enumerate(labels)}\n",
        "\n",
        "        for i, test in enumerate(tests):\n",
        "            start = time.clock()\n",
        "            ar = knn.analyze(test)\n",
        "            result = KNearestNeighbour.verdict(ar, k)\n",
        "            end = time.clock()\n",
        "            total_time += end - start\n",
        "            if expected_labels[i] == result:\n",
        "                success_count += 1\n",
        "            else:\n",
        "                failed_tests.append((test, KNearestNeighbour.explain(ar, k), expected_labels[i]))\n",
        "            if build_confusion_matrix:\n",
        "                confusion_matrix[labels_mapping[expected_labels[i]], labels_mapping[result]] += 1\n",
        "\n",
        "        success_rate = success_count / len(tests)\n",
        "\n",
        "        return total_time, success_rate, failed_tests, confusion_matrix, labels_mapping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RUmX5mjCaFWG",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title KNearestNeighbour with PCA=10, KNN=3, Accu=0.969\n",
        "# Run custom KNN\n",
        "\n",
        "train = train_data_N.copy()\n",
        "test  = test_data_N.copy()\n",
        "\n",
        "knn = KNearestNeighbour(train, 'activity', 10)\n",
        "t = KNearestNeighbour.test_model(knn, 3, test, build_confusion_matrix=True)\n",
        "\n",
        "print('Acuracy')\n",
        "print(t[1])\n",
        "\n",
        "print('Confusion Maxtrix')\n",
        "print(t[3])\n",
        "sns.heatmap(t[3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ETkL0tJ6VRhR",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title KNearestNeighbour with PCA=1, KNN=1, Accuracy= 0.927\n",
        "knn = KNearestNeighbour(data, 'activity', 1)\n",
        "t = KNearestNeighbour.test_model(knn, 1, tests, build_confusion_matrix=True)\n",
        "\n",
        "print('Acuracy')\n",
        "print(t[1])\n",
        "\n",
        "print('Confusion Maxtrix')\n",
        "print(t[3])\n",
        "sns.heatmap(t[3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g9h2vD8XEkKb",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title KNeighborsClassifier PCA=10, KNN=3, Accu=0.971\n",
        "#Run scikitlearn with pca, KNN\n",
        "\n",
        "# split out activity (target column) to Y\n",
        "train = train_data_N.copy()\n",
        "test  = test_data_N.copy()\n",
        "Y = train.pop('activity')\n",
        "X = train\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
        "\n",
        "#Apply PCA\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=10)\n",
        "X1 = pca.fit_transform(X_train)\n",
        "\n",
        "\n",
        "#-------------\n",
        "#default training method\n",
        "knn_model = KNeighborsClassifier(algorithm='brute',n_neighbors=3)\n",
        "knn_model.fit(X1, Y_train)\n",
        "\n",
        "#test predict\n",
        "pca = PCA(n_components=10)\n",
        "actualResult = test.pop('activity')\n",
        "\n",
        "Xtest = pca.fit_transform(test)\n",
        "\n",
        "predictions = knn_model.predict(Xtest)\n",
        "#print(predictions)\n",
        "knn_model.score(X1,Y_train)\n",
        "# 0.9866999168744804\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "\n",
        "cm = accuracy_score(actualResult, predictions)\n",
        "print(cm)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xPzQs14PcI9m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title KNearestNeighbour table { display-mode: \"code\" }\n",
        "# Run custom KNN\n",
        "\n",
        "train = train_data_N.copy()\n",
        "test  = test_data_N.copy()\n",
        "\n",
        "# pca=500,knn=3\n",
        "knn = KNearestNeighbour(train, 'activity', 500)\n",
        "t = KNearestNeighbour.test_model(knn, 3, test, build_confusion_matrix=True)\n",
        "\n",
        "print('Acuracy:')\n",
        "print(t[1])\n",
        "print('Confusion Maxtrix')\n",
        "print(t[3])\n",
        "\n",
        "train = train_data_N.copy()\n",
        "test  = test_data_N.copy()\n",
        "\n",
        "# pca=250,knn=3\n",
        "knn = KNearestNeighbour(train, 'activity', 250)\n",
        "t = KNearestNeighbour.test_model(knn, 3, test, build_confusion_matrix=True)\n",
        "\n",
        "print('Acuracy:')\n",
        "print(t[1])\n",
        "print('Confusion Maxtrix')\n",
        "print(t[3])\n",
        "\n",
        "\n",
        "train = train_data_N.copy()\n",
        "test  = test_data_N.copy()\n",
        "\n",
        "# pca=100,knn=3\n",
        "knn = KNearestNeighbour(train, 'activity', 100)\n",
        "t = KNearestNeighbour.test_model(knn, 3, test, build_confusion_matrix=True)\n",
        "\n",
        "print('Acuracy:')\n",
        "print(t[1])\n",
        "print('Confusion Maxtrix')\n",
        "print(t[3])\n",
        "\n",
        "\n",
        "train = train_data_N.copy()\n",
        "test  = test_data_N.copy()\n",
        "\n",
        "# pca=50,knn=3\n",
        "knn = KNearestNeighbour(train, 'activity', 50)\n",
        "t = KNearestNeighbour.test_model(knn, 3, test, build_confusion_matrix=True)\n",
        "\n",
        "print('Acuracy:')\n",
        "print(t[1])\n",
        "print('Confusion Maxtrix')\n",
        "print(t[3])\n",
        "\n",
        "\n",
        "train = train_data_N.copy()\n",
        "test  = test_data_N.copy()\n",
        "\n",
        "# pca=10,knn=3\n",
        "knn = KNearestNeighbour(train, 'activity', 10)\n",
        "t = KNearestNeighbour.test_model(knn, 3, test, build_confusion_matrix=True)\n",
        "\n",
        "print('Acuracy:')\n",
        "print(t[1])\n",
        "print('Confusion Maxtrix')\n",
        "print(t[3])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-Gdrf4hdc1lL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Backup\n",
        "\n",
        "##Upload files to Colab\n",
        "```\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "files.os.listdir()\n",
        "```\n",
        "\n",
        "##Download dataset from Kaggle\n",
        "```\n",
        "!pip install kaggle\n",
        "!mkdir .kaggle\n",
        "\n",
        "import json\n",
        "token = {\"username\":\"nguyentuananh\",\"key\":\"44e2c22b301712101fdafe3d03ff7898\"}\n",
        "with open('.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)\n",
        "!chmod 600 .kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d mboaglio/simplifiedhuarus\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "JO16aobCOIMR",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "!pip install umap-learn\n",
        "#First we reduce original train_data with UMAP\n",
        "#Then run the fit with KNN model\n",
        "\n",
        "train_data = pd.read_csv('train.csv')\n",
        "y = train_data.pop('activity')\n",
        "x = train_data\n",
        "\n",
        "# initialize UMAP\n",
        "reducer = umap.UMAP(random_state=42)\n",
        "embedding = reducer.fit_transform(x)\n",
        "\n",
        "# fit model based on the embedding\n",
        "knn_model = KNeighborsClassifier(algorithm='brute',n_neighbors=3)\n",
        "knn_model.fit(embedding,y)\n",
        "\n",
        "test_data = pd.read_csv('test.csv')\n",
        "#????not sure trying to transform the test data before testing is correct, but just give it a try\n",
        "embedding_test = reducer.fit_transform(test_data)\n",
        "\n",
        "predictions = knn_model.predict(embedding_test)\n",
        "print(predictions)\n",
        "#not as expected - FAILED\n",
        "#how to use the test data, if the original train data already reduced?\n",
        "knn_model.score(embedding,y)\n",
        "#0.9542809642560266 - not as expected - FAILED"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5ytJB0Kdaq-k",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "#@title\n",
        "!ls -a\n",
        "#cd ..\n",
        "#!pwd\n",
        "#cd /content\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}