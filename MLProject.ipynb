{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLProject.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ntuananh/CS582_MachineLearning/blob/master/MLProject.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "qBqPsRXMZrux",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "https://www.youtube.com/watch?v=XOEN9W05_4A - video demo for capturing data\n",
        "\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "XaYZoluuY8eE",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Setup Enviroment & Import Data\n",
        "# Read data from Google Drive\n",
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import pandas as pd\n",
        " \n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "#List files\n",
        "#file_list = drive.ListFile({'q': \"'11f05x7C5kbWdpTdRJVwbPgV7MOG_D6fv' in parents and trashed=false\"}).GetList()\n",
        "#for file1 in file_list:\n",
        "#  print('title: %s, id: %s' % (file1['title'], file1['id']))\n",
        "  \n",
        "# create Files and pull content to Colab\n",
        "train_N = drive.CreateFile({'id': '1qAj6Hqqoss0bAuYuVWGSoOZgmvMkZ6k2'})\n",
        "train_N.GetContentFile('train_N.csv')\n",
        "test_N = drive.CreateFile({'id': '1hv9hqdvvTMJGPPqMTsd0YS58_0nio97G'})\n",
        "test_N.GetContentFile('test_N.csv')\n",
        "\n",
        "train = drive.CreateFile({'id': '1mXbabpIXPB_57pOvam9bjKOBVnQAoeML'})\n",
        "train.GetContentFile('train.csv')\n",
        "test = drive.CreateFile({'id': '1JjEDt8q_VPWfVCN7MOexIwY1I1GtTLfC'})\n",
        "test.GetContentFile('test.csv')\n",
        "\n",
        "# read files'content into dataframe\n",
        "train_data = pd.read_csv('train.csv')\n",
        "test_data = pd.read_csv('test.csv')\n",
        "train_data_N = pd.read_csv('train_N.csv')\n",
        "test_data_N = pd.read_csv('test_N.csv')\n",
        "\n",
        "print('done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GUgg6xmcLtBA",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Import libraries\n",
        "#import Libs\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print('done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qYninXyVB_i5",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "#@title KDTree\n",
        "#https://en.wikipedia.org/wiki/K-d_tree\n",
        "  \n",
        "from collections import namedtuple\n",
        "from operator import itemgetter\n",
        "from pprint import pformat\n",
        "\n",
        "class Node(namedtuple('Node', 'location left_child right_child')):\n",
        "    def __repr__(self):\n",
        "        return pformat(tuple(self))\n",
        "\n",
        "def kdtree(point_list, depth=0):\n",
        "    try:\n",
        "        k = len(point_list[0]) # assumes all points have the same dimension\n",
        "    except IndexError as e: # if not point_list:\n",
        "        return None\n",
        "    # Select axis based on depth so that axis cycles through all valid values\n",
        "    axis = depth % k\n",
        " \n",
        "    # Sort point list and choose median as pivot element\n",
        "    point_list.sort(key=itemgetter(axis))\n",
        "    median = len(point_list) // 2 # choose median\n",
        " \n",
        "    # Create node and construct subtrees\n",
        "    return Node(\n",
        "        location=point_list[median],\n",
        "        left_child=kdtree(point_list[:median], depth + 1),\n",
        "        right_child=kdtree(point_list[median + 1:], depth + 1)\n",
        "    )\n",
        "\n",
        "def main():\n",
        "    \"\"\"Example usage\"\"\"\n",
        "    point_list = [(2,3), (5,4), (9,6), (4,7), (8,1), (7,2)]\n",
        "    tree = kdtree(point_list)\n",
        "    print(tree)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HsLr7wYfPdS2",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "#@title KNearestNeighbour Class\n",
        "# Custom KNN \n",
        "import time\n",
        "import collections\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "class KNearestNeighbour:\n",
        "    def __init__(self, data: pd.DataFrame, label_column: str, data_dimension: int=-1):\n",
        "        _ = data.copy()\n",
        "        self.label_column = label_column\n",
        "        self.labels = _.pop(label_column)\n",
        "        self.properties = _.values\n",
        "        self.size = len(self.labels)\n",
        "\n",
        "        self.data_dimension = data_dimension\n",
        "        if data_dimension > 0:\n",
        "            red_dim = self.pca(self.properties, data_dimension)\n",
        "            self.properties = red_dim[0]\n",
        "            self.mean = red_dim[1]\n",
        "            self.ev = red_dim[2]\n",
        "\n",
        "        self.temp = self.properties.tolist()\n",
        "        for l in self.temp:\n",
        "            for i in range(len(l)):\n",
        "                l[i] = l[i].real\n",
        "        self.temp = [(e, i) for i, e in enumerate(self.temp)]\n",
        "\n",
        "        self.kd = self.build_kd_tree(self.temp)\n",
        "\n",
        "        self.k = None\n",
        "        self.max_k = self.size ** 0.5\n",
        "\n",
        "    # TODO: add find_dim method for find the optimal data dimension\n",
        "    @classmethod\n",
        "    def find_k(cls, data, label_column, max_k=-1, data_dimension=-1):\n",
        "        data_splits = [[] for _ in range(5)]\n",
        "        sid, accuracies = 0, {}\n",
        "        for d in data.values:\n",
        "            data_splits[sid].append(d)\n",
        "            sid = sid + 1 if sid < 4 else 0\n",
        "        df_splits = [pd.DataFrame(data=data_splits[i], columns=data.columns) for i in range(5)]\n",
        "        for i in range(5):\n",
        "            print(i)\n",
        "            train = pd.concat([df_splits[j] for j in range(5) if j != i], ignore_index=True)\n",
        "            test = df_splits[i]\n",
        "            knn = KNearestNeighbour(train, label_column, data_dimension)\n",
        "            if max_k < 1:\n",
        "                # m_k = int(len(data) ** 0.5)\n",
        "                m_k = 10\n",
        "            else:\n",
        "                m_k = max_k\n",
        "            for k in range(1, m_k + 1, 2):\n",
        "                rate = KNearestNeighbour.test_model(knn, k, test)[1]\n",
        "                accuracies[k] = accuracies.get(k, 0) + rate\n",
        "        for k in accuracies:\n",
        "            accuracies[k] /= 5\n",
        "        return max(accuracies.keys(), key=(lambda key: accuracies[key]))\n",
        "\n",
        "    @classmethod\n",
        "    def manhattan_distance(cls, p1: list, p2: list) -> float:\n",
        "        return sum([abs(e[0] - e[1]) for e in zip(p1, p2)])\n",
        "\n",
        "    def analyze(self, test_data: list) -> list:\n",
        "        if self.data_dimension > 0:\n",
        "            test_data = np.transpose(np.dot(np.transpose(self.ev), np.transpose(np.array(test_data) - self.mean)))\n",
        "        r = []\n",
        "        for i in range(self.size):\n",
        "            r.append((KNearestNeighbour.manhattan_distance(test_data, self.properties[i]), i))\n",
        "\n",
        "        r.sort(key=lambda e: e[0])\n",
        "        return [self.labels[r[i][1]] for i in range(int(self.size ** 0.5))]\n",
        "\n",
        "    def kd_tree_analyze(self, test_data: list, k: int):\n",
        "        if self.data_dimension > 0:\n",
        "            test_data = np.transpose(np.dot(np.transpose(self.ev), np.transpose(np.array(test_data) - self.mean)))\n",
        "        search_result = self.kd_search(self.kd, test_data, k)\n",
        "        return [self.labels[search_result[i].original_index] for i in range(k)]\n",
        "\n",
        "    @classmethod\n",
        "    def kd_tree_verdict(cls, nearest_neighbours, k: int):\n",
        "        return collections.Counter(nearest_neighbours[:min(k, len(nearest_neighbours))]).most_common(1)[0][0]\n",
        "\n",
        "    @classmethod\n",
        "    def verdict(cls, nearest_neighbours: list, k: int):\n",
        "        return collections.Counter(nearest_neighbours[:min(k, len(nearest_neighbours))]).most_common(1)[0][0]\n",
        "\n",
        "    @classmethod\n",
        "    def explain(cls, nearest_neighbours: list, k: int):\n",
        "        d = dict(collections.Counter(nearest_neighbours[:min(k, len(nearest_neighbours))]).most_common())\n",
        "        return {e: d[e]/k for e in d}\n",
        "\n",
        "    @classmethod\n",
        "    def pca(cls, data, n_components):\n",
        "        mean = np.mean(data, axis=0)\n",
        "        data -= mean\n",
        "        cov_matrix = np.cov(np.transpose(data))\n",
        "\n",
        "        eigen_values, eigen_vectors = np.linalg.eig(cov_matrix)\n",
        "        indices = np.argsort(eigen_values)[::-1]\n",
        "        eigen_vectors = eigen_vectors[:, indices]\n",
        "        eigen_vectors = eigen_vectors[:, :n_components]\n",
        "        for i in range(np.shape(eigen_vectors)[1]):\n",
        "            eigen_vectors[:, i] /= np.linalg.norm(eigen_vectors[:, i])\n",
        "\n",
        "        transformed_data = np.transpose(np.dot(np.transpose(eigen_vectors), np.transpose(data)))\n",
        "        # original_data = np.transpose(np.dot(evecs, x)) + m\n",
        "        return transformed_data, mean, eigen_vectors\n",
        "\n",
        "    @classmethod\n",
        "    def test_model(cls, model, k: int, tests: pd.DataFrame, build_confusion_matrix: bool=False):\n",
        "        _ = tests.copy()\n",
        "        expected_labels = _.pop(model.label_column)\n",
        "        tests = _.values\n",
        "\n",
        "        success_count = 0\n",
        "        failed_tests = []\n",
        "        total_time = 0\n",
        "\n",
        "        confusion_matrix = None\n",
        "        labels_mapping = None\n",
        "        if build_confusion_matrix:\n",
        "            labels = np.unique(np.array(model.labels))\n",
        "            confusion_matrix = np.zeros((len(labels), len(labels)))\n",
        "            labels_mapping = {l: i for i, l in enumerate(labels)}\n",
        "\n",
        "        for i, test in enumerate(tests):\n",
        "            start = time.clock()\n",
        "            ar = model.analyze(test)\n",
        "            result = KNearestNeighbour.verdict(ar, k)\n",
        "\n",
        "#             node = model.kd_tree_analyze(test, k)\n",
        "#             result = KNearestNeighbour.kd_tree_verdict(node, k)\n",
        "\n",
        "            end = time.clock()\n",
        "            total_time += end - start\n",
        "            if expected_labels[i] == result:\n",
        "                success_count += 1\n",
        "            # else:\n",
        "            #     failed_tests.append((test, KNearestNeighbour.explain(ar, k), expected_labels[i]))\n",
        "            if build_confusion_matrix:\n",
        "                confusion_matrix[labels_mapping[expected_labels[i]], labels_mapping[result]] += 1\n",
        "\n",
        "        success_rate = success_count / len(tests)\n",
        "\n",
        "        return total_time, success_rate, failed_tests, confusion_matrix, labels_mapping\n",
        "\n",
        "    class Node:\n",
        "        def __init__(self, original_index, location, left, right):\n",
        "            self.original_index = original_index\n",
        "            self.location = location\n",
        "            self.left = left\n",
        "            self.right = right\n",
        "\n",
        "    @classmethod\n",
        "    def build_kd_tree(cls, points, depth=0):\n",
        "        data_size = len(points)\n",
        "        if data_size < 1:\n",
        "            return None\n",
        "        axis = depth % len(points[0][0])\n",
        "        points.sort(key=lambda e: e[0][axis])\n",
        "        median = data_size // 2\n",
        "        while median + 1 < data_size and points[median][0][axis] == points[median + 1][0][axis]:\n",
        "            median += 1\n",
        "        return cls.Node(\n",
        "            points[median][1],\n",
        "            points[median][0],\n",
        "            cls.build_kd_tree(points[:median], depth + 1),\n",
        "            cls.build_kd_tree(points[median + 1:], depth + 1)\n",
        "        )\n",
        "\n",
        "    @classmethod\n",
        "    def euclidean_distance(cls, p1: list, p2: list) -> float:\n",
        "        return sum(np.square(np.array(p1) - np.array(p2))) ** 0.5\n",
        "\n",
        "    # The algorithm can be extended in several ways by simple modifications.\n",
        "    # It can provide the k nearest neighbours to a point by maintaining k current bests instead of just one.\n",
        "    # A branch is only eliminated when k points have been found and the branch cannot have points closer\n",
        "    # than any of the k current bests.\n",
        "    def kd_search(self, kd_tree, test_data, k: int):\n",
        "        kml = KNearestNeighbour.KMinList(k)\n",
        "\n",
        "        def _kd_search(kd_tree, test_data, depth=0):\n",
        "            if kd_tree is None:\n",
        "                return\n",
        "            nonlocal kml\n",
        "\n",
        "            axis = depth % len(test_data)\n",
        "            goes_left = True\n",
        "            if test_data[axis] <= kd_tree.location[axis]:\n",
        "                _kd_search(kd_tree.left, test_data, depth + 1)\n",
        "            else:\n",
        "                goes_left = False\n",
        "                _kd_search(kd_tree.right, test_data, depth + 1)\n",
        "\n",
        "            dist = KNearestNeighbour.manhattan_distance(test_data, kd_tree.location)\n",
        "            kml.insert((dist, kd_tree))\n",
        "\n",
        "            splitting_coor_diff = abs(test_data[axis] - kd_tree.location[axis])\n",
        "            max_nearest_dist = kml.max()[0]\n",
        "\n",
        "            if not kml.is_full() or splitting_coor_diff < max_nearest_dist:\n",
        "                if goes_left:\n",
        "                    _kd_search(kd_tree.right, test_data, depth + 1)\n",
        "                else:\n",
        "                    _kd_search(kd_tree.left, test_data, depth + 1)\n",
        "\n",
        "        _kd_search(kd_tree, test_data)\n",
        "        return [e[1] for e in kml.elements()]\n",
        "\n",
        "    class KMinList:\n",
        "        class Node:\n",
        "            def __init__(self, element):\n",
        "                self.element = element\n",
        "                self.next, self.prev = None, None\n",
        "\n",
        "        def __init__(self, k: int):\n",
        "            self.k = k\n",
        "            self.len = 0\n",
        "            self.head, self.tail = None, None\n",
        "\n",
        "        def insert_before(self, node, new_node):\n",
        "            if self.head is None:\n",
        "                self.head = new_node\n",
        "                self.tail = self.head\n",
        "            elif self.head == node:\n",
        "                self.head.prev = new_node\n",
        "                new_node.next = self.head\n",
        "                self.head = new_node\n",
        "            else:\n",
        "                prev_node = node.prev\n",
        "                prev_node.next = new_node\n",
        "                new_node.prev = prev_node\n",
        "                node.prev = new_node\n",
        "                new_node.next = node\n",
        "\n",
        "        def insert(self, element):\n",
        "            new_node = KNearestNeighbour.KMinList.Node(element)\n",
        "            key = element[0]\n",
        "            if self.tail is not None and self.tail.element[0] < key:\n",
        "                self.tail.next = new_node\n",
        "                new_node.prev = self.tail\n",
        "                self.tail = new_node\n",
        "            else:\n",
        "                p = self.head\n",
        "                while p is not None and p.element[0] < key:\n",
        "                    p = p.next\n",
        "                self.insert_before(p, new_node)\n",
        "            self.len += 1\n",
        "            if self.len > self.k:\n",
        "                self.len = self.k\n",
        "                self.tail = self.tail.prev\n",
        "                self.tail.next = None\n",
        "\n",
        "        def is_full(self):\n",
        "            return self.len == self.k\n",
        "\n",
        "        def elements(self):\n",
        "            result = []\n",
        "            p = self.head\n",
        "            while p is not None:\n",
        "                result.append(p.element)\n",
        "                p = p.next\n",
        "            return result\n",
        "\n",
        "        def max(self):\n",
        "            return self.tail.element\n",
        "\n",
        "\n",
        "#data = pd.read_csv(r'..\\data\\human_act_recognition\\train.csv')\n",
        "#tests = pd.read_csv(r'..\\data\\human_act_recognition\\test.csv')\n",
        "#knn = KNearestNeighbour(data, 'activity', 10)\n",
        "\n",
        "# suggested_k = KNearestNeighbour.find_k(data, 'activity', 10)\n",
        "# print(suggested_k)\n",
        "#t = KNearestNeighbour.test_model(knn, 1, tests)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RUmX5mjCaFWG",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title KNearestNeighbour with PCA=10, KNN=3, Accu=0.969\n",
        "# Run custom KNN\n",
        "\n",
        "train = train_data_N.copy()\n",
        "test  = test_data_N.copy()\n",
        "\n",
        "knn = KNearestNeighbour(train, 'activity', 10)\n",
        "t   = KNearestNeighbour.test_model(knn, 3, test, build_confusion_matrix=True)\n",
        "\n",
        "print('Acuracy')\n",
        "print(t[1])\n",
        "\n",
        "print('Confusion Maxtrix')\n",
        "print(t[3])\n",
        "sns.heatmap(t[3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ETkL0tJ6VRhR",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title KNearestNeighbour with PCA=1, KNN=1, Accuracy= 0.927\n",
        "knn = KNearestNeighbour(data, 'activity', 1)\n",
        "t = KNearestNeighbour.test_model(knn, 1, tests, build_confusion_matrix=True)\n",
        "\n",
        "print('Acuracy')\n",
        "print(t[1])\n",
        "\n",
        "print('Confusion Maxtrix')\n",
        "print(t[3])\n",
        "sns.heatmap(t[3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g9h2vD8XEkKb",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title KNeighborsClassifier PCA=10, KNN=3, Accu=0.971\n",
        "#Run scikitlearn with pca, KNN\n",
        "\n",
        "# split out activity (target column) to Y\n",
        "train = train_data_N.copy()\n",
        "test  = test_data_N.copy()\n",
        "Y = train.pop('activity')\n",
        "X = train\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)\n",
        "\n",
        "#Apply PCA\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=10)\n",
        "X1 = pca.fit_transform(X_train)\n",
        "\n",
        "\n",
        "#-------------\n",
        "#default training method\n",
        "knn_model = KNeighborsClassifier(algorithm='brute',n_neighbors=3)\n",
        "knn_model.fit(X1, Y_train)\n",
        "\n",
        "#test predict\n",
        "pca = PCA(n_components=10)\n",
        "actualResult = test.pop('activity')\n",
        "\n",
        "Xtest = pca.fit_transform(test)\n",
        "\n",
        "predictions = knn_model.predict(Xtest)\n",
        "#print(predictions)\n",
        "knn_model.score(X1,Y_train)\n",
        "# 0.9866999168744804\n",
        "\n",
        "# Making the Confusion Matrix\n",
        "\n",
        "cm = accuracy_score(actualResult, predictions)\n",
        "print(cm)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xPzQs14PcI9m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "3f1dbd98-b830-4e84-95fc-11f74ed979c8"
      },
      "cell_type": "code",
      "source": [
        "#@title KNearestNeighbour table { display-mode: \"code\" }\n",
        "# Run custom KNN\n",
        "\n",
        "train = train_data_N.copy()\n",
        "test  = test_data_N.copy()\n",
        "\n",
        "# pca=500,knn=3\n",
        "knn = KNearestNeighbour(train, 'activity', 500)\n",
        "t = KNearestNeighbour.test_model(knn, 3, test, build_confusion_matrix=True)\n",
        "\n",
        "print('pca=500,knn=3, Acuracy:')\n",
        "print(t[1])\n",
        "print('Confusion Maxtrix')\n",
        "print(t[3])\n",
        "\n",
        "train = train_data_N.copy()\n",
        "test  = test_data_N.copy()\n",
        "\n",
        "# pca=250,knn=3\n",
        "knn = KNearestNeighbour(train, 'activity', 250)\n",
        "t = KNearestNeighbour.test_model(knn, 3, test, build_confusion_matrix=True)\n",
        "\n",
        "print('pca=250,knn=3, Acuracy:')\n",
        "print(t[1])\n",
        "print('Confusion Maxtrix')\n",
        "print(t[3])\n",
        "\n",
        "\n",
        "train = train_data_N.copy()\n",
        "test  = test_data_N.copy()\n",
        "\n",
        "# pca=100,knn=3\n",
        "knn = KNearestNeighbour(train, 'activity', 100)\n",
        "t = KNearestNeighbour.test_model(knn, 3, test, build_confusion_matrix=True)\n",
        "\n",
        "print('pca=100,knn=3, Acuracy:')\n",
        "print(t[1])\n",
        "print('Confusion Maxtrix')\n",
        "print(t[3])\n",
        "\n",
        "\n",
        "train = train_data_N.copy()\n",
        "test  = test_data_N.copy()\n",
        "\n",
        "# pca=50,knn=3\n",
        "knn = KNearestNeighbour(train, 'activity', 50)\n",
        "t = KNearestNeighbour.test_model(knn, 3, test, build_confusion_matrix=True)\n",
        "\n",
        "print('pca=50,knn=3, Acuracy:')\n",
        "print(t[1])\n",
        "print('Confusion Maxtrix')\n",
        "print(t[3])\n",
        "\n",
        "\n",
        "train = train_data_N.copy()\n",
        "test  = test_data_N.copy()\n",
        "\n",
        "# pca=10,knn=3\n",
        "knn = KNearestNeighbour(train, 'activity', 10)\n",
        "t = KNearestNeighbour.test_model(knn, 3, test, build_confusion_matrix=True)\n",
        "\n",
        "print('pca=10,knn=3, Acuracy:')\n",
        "print(t[1])\n",
        "print('Confusion Maxtrix')\n",
        "print(t[3])\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pca=500,knn=3, Acuracy:\n",
            "0.969521044992743\n",
            "Confusion Maxtrix\n",
            "[[123.   7.   0.   0.   0.   0.]\n",
            " [  0. 105.   4.   0.   0.   0.]\n",
            " [  0.   2. 117.   0.   0.   2.]\n",
            " [  0.   0.   0. 109.   0.   0.]\n",
            " [  0.   0.   0.   4. 101.   2.]\n",
            " [  0.   0.   0.   0.   0. 113.]]\n",
            "pca=250,knn=3, Acuracy:\n",
            "0.9709724238026125\n",
            "Confusion Maxtrix\n",
            "[[124.   6.   0.   0.   0.   0.]\n",
            " [  0. 105.   4.   0.   0.   0.]\n",
            " [  0.   2. 117.   0.   0.   2.]\n",
            " [  0.   0.   0. 109.   0.   0.]\n",
            " [  0.   0.   0.   4. 101.   2.]\n",
            " [  0.   0.   0.   0.   0. 113.]]\n",
            "pca=100,knn=3, Acuracy:\n",
            "0.9724238026124818\n",
            "Confusion Maxtrix\n",
            "[[125.   5.   0.   0.   0.   0.]\n",
            " [  0. 106.   3.   0.   0.   0.]\n",
            " [  0.   2. 117.   0.   0.   2.]\n",
            " [  0.   0.   0. 108.   1.   0.]\n",
            " [  0.   0.   0.   4. 101.   2.]\n",
            " [  0.   0.   0.   0.   0. 113.]]\n",
            "pca=50,knn=3, Acuracy:\n",
            "0.9709724238026125\n",
            "Confusion Maxtrix\n",
            "[[125.   4.   0.   1.   0.   0.]\n",
            " [  0. 106.   3.   0.   0.   0.]\n",
            " [  0.   1. 118.   0.   0.   2.]\n",
            " [  0.   0.   0. 108.   1.   0.]\n",
            " [  0.   0.   0.   4.  99.   4.]\n",
            " [  0.   0.   0.   0.   0. 113.]]\n",
            "pca=10,knn=3, Acuracy:\n",
            "0.969521044992743\n",
            "Confusion Maxtrix\n",
            "[[126.   3.   0.   1.   0.   0.]\n",
            " [  0. 106.   3.   0.   0.   0.]\n",
            " [  0.   1. 117.   0.   0.   3.]\n",
            " [  0.   0.   0. 108.   1.   0.]\n",
            " [  0.   0.   0.   3.  98.   6.]\n",
            " [  0.   0.   0.   0.   0. 113.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IzcpiQSMmR6a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "1ca710f4-c45e-4bac-82e7-1d3238ea74ba"
      },
      "cell_type": "code",
      "source": [
        "#@title KNearestNeighbour table { display-mode: \"code\" }\n",
        "# Run custom KNN\n",
        "\n",
        "train = train_data_N.copy()\n",
        "test  = test_data_N.copy()\n",
        "\n",
        "# pca=500,knn=1\n",
        "knn = KNearestNeighbour(train, 'activity', 500)\n",
        "t = KNearestNeighbour.test_model(knn, 1, test, build_confusion_matrix=True)\n",
        "\n",
        "print('pca=500,knn=1, Acuracy:')\n",
        "print(t[1])\n",
        "print('Confusion Maxtrix')\n",
        "print(t[3])\n",
        "\n",
        "train = train_data_N.copy()\n",
        "test  = test_data_N.copy()\n",
        "\n",
        "# pca=250,knn=1\n",
        "knn = KNearestNeighbour(train, 'activity', 250)\n",
        "t = KNearestNeighbour.test_model(knn, 1, test, build_confusion_matrix=True)\n",
        "\n",
        "print('pca=250,knn=1, Acuracy:')\n",
        "print(t[1])\n",
        "print('Confusion Maxtrix')\n",
        "print(t[3])\n",
        "\n",
        "\n",
        "train = train_data_N.copy()\n",
        "test  = test_data_N.copy()\n",
        "\n",
        "# pca=100,knn=1\n",
        "knn = KNearestNeighbour(train, 'activity', 100)\n",
        "t = KNearestNeighbour.test_model(knn, 1, test, build_confusion_matrix=True)\n",
        "\n",
        "print('pca=100,knn=1, Acuracy:')\n",
        "print(t[1])\n",
        "print('Confusion Maxtrix')\n",
        "print(t[3])\n",
        "\n",
        "\n",
        "train = train_data_N.copy()\n",
        "test  = test_data_N.copy()\n",
        "\n",
        "# pca=50,knn=1\n",
        "knn = KNearestNeighbour(train, 'activity', 50)\n",
        "t = KNearestNeighbour.test_model(knn, 1, test, build_confusion_matrix=True)\n",
        "\n",
        "print('pca=50,knn=1, Acuracy:')\n",
        "print(t[1])\n",
        "print('Confusion Maxtrix')\n",
        "print(t[3])\n",
        "\n",
        "\n",
        "train = train_data_N.copy()\n",
        "test  = test_data_N.copy()\n",
        "\n",
        "# pca=10,knn=1\n",
        "knn = KNearestNeighbour(train, 'activity', 10)\n",
        "t = KNearestNeighbour.test_model(knn, 1, test, build_confusion_matrix=True)\n",
        "\n",
        "print('pca=10,knn=1, Acuracy:')\n",
        "print(t[1])\n",
        "print('Confusion Maxtrix')\n",
        "print(t[3])\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pca=500,knn=1, Acuracy:\n",
            "0.9854862119013063\n",
            "Confusion Maxtrix\n",
            "[[129.   1.   0.   0.   0.   0.]\n",
            " [  0. 105.   4.   0.   0.   0.]\n",
            " [  0.   1. 119.   0.   0.   1.]\n",
            " [  0.   0.   0. 109.   0.   0.]\n",
            " [  0.   0.   0.   1. 104.   2.]\n",
            " [  0.   0.   0.   0.   0. 113.]]\n",
            "pca=250,knn=1, Acuracy:\n",
            "0.9869375907111756\n",
            "Confusion Maxtrix\n",
            "[[130.   0.   0.   0.   0.   0.]\n",
            " [  0. 105.   4.   0.   0.   0.]\n",
            " [  0.   1. 119.   0.   0.   1.]\n",
            " [  0.   0.   0. 109.   0.   0.]\n",
            " [  0.   0.   0.   1. 104.   2.]\n",
            " [  0.   0.   0.   0.   0. 113.]]\n",
            "pca=100,knn=1, Acuracy:\n",
            "0.988388969521045\n",
            "Confusion Maxtrix\n",
            "[[130.   0.   0.   0.   0.   0.]\n",
            " [  0. 106.   3.   0.   0.   0.]\n",
            " [  0.   1. 119.   0.   0.   1.]\n",
            " [  0.   0.   0. 109.   0.   0.]\n",
            " [  0.   0.   0.   1. 104.   2.]\n",
            " [  0.   0.   0.   0.   0. 113.]]\n",
            "pca=50,knn=1, Acuracy:\n",
            "0.9912917271407837\n",
            "Confusion Maxtrix\n",
            "[[130.   0.   0.   0.   0.   0.]\n",
            " [  0. 108.   1.   0.   0.   0.]\n",
            " [  0.   1. 119.   0.   0.   1.]\n",
            " [  0.   0.   0. 109.   0.   0.]\n",
            " [  0.   0.   0.   2. 104.   1.]\n",
            " [  0.   0.   0.   0.   0. 113.]]\n",
            "pca=10,knn=1, Acuracy:\n",
            "0.9927431059506531\n",
            "Confusion Maxtrix\n",
            "[[130.   0.   0.   0.   0.   0.]\n",
            " [  0. 107.   2.   0.   0.   0.]\n",
            " [  0.   0. 120.   0.   0.   1.]\n",
            " [  0.   0.   0. 109.   0.   0.]\n",
            " [  0.   0.   0.   0. 106.   1.]\n",
            " [  0.   0.   0.   0.   1. 112.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AhG1CYOUgw3O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "a5402b5c-deb7-4e8f-8641-04ec8e5fdb2c"
      },
      "cell_type": "code",
      "source": [
        "train = train_data_N.copy()\n",
        "test  = test_data_N.copy()\n",
        "\n",
        "# pca=1,knn=1\n",
        "knn = KNearestNeighbour(train, 'activity',10)\n",
        "t = KNearestNeighbour.test_model(knn, 1, test, build_confusion_matrix=True)\n",
        "\n",
        "print('pca=1,knn=1, Acuracy:')\n",
        "print(t[1])\n",
        "print('time:')\n",
        "print(t[0])\n",
        "print('Confusion Maxtrix')\n",
        "print(t[3])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pca=1,knn=1, Acuracy:\n",
            "0.9927431059506531\n",
            "time:\n",
            "24.579424999997173\n",
            "Confusion Maxtrix\n",
            "[[130.   0.   0.   0.   0.   0.]\n",
            " [  0. 107.   2.   0.   0.   0.]\n",
            " [  0.   0. 120.   0.   0.   1.]\n",
            " [  0.   0.   0. 109.   0.   0.]\n",
            " [  0.   0.   0.   0. 106.   1.]\n",
            " [  0.   0.   0.   0.   1. 112.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-Gdrf4hdc1lL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Backup\n",
        "\n",
        "##Upload files to Colab\n",
        "```\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "files.os.listdir()\n",
        "```\n",
        "\n",
        "##Download dataset from Kaggle\n",
        "```\n",
        "!pip install kaggle\n",
        "!mkdir .kaggle\n",
        "\n",
        "import json\n",
        "token = {\"username\":\"nguyentuananh\",\"key\":\"44e2c22b301712101fdafe3d03ff7898\"}\n",
        "with open('.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)\n",
        "!chmod 600 .kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d mboaglio/simplifiedhuarus\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "JO16aobCOIMR",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title UMAP\n",
        "!pip install umap-learn\n",
        "#First we reduce original train_data with UMAP\n",
        "#Then run the fit with KNN model\n",
        "\n",
        "train_data = pd.read_csv('train.csv')\n",
        "y = train_data.pop('activity')\n",
        "x = train_data\n",
        "\n",
        "# initialize UMAP\n",
        "reducer = umap.UMAP(random_state=42)\n",
        "embedding = reducer.fit_transform(x)\n",
        "\n",
        "# fit model based on the embedding\n",
        "knn_model = KNeighborsClassifier(algorithm='brute',n_neighbors=3)\n",
        "knn_model.fit(embedding,y)\n",
        "\n",
        "test_data = pd.read_csv('test.csv')\n",
        "#????not sure trying to transform the test data before testing is correct, but just give it a try\n",
        "embedding_test = reducer.fit_transform(test_data)\n",
        "\n",
        "predictions = knn_model.predict(embedding_test)\n",
        "print(predictions)\n",
        "#not as expected - FAILED\n",
        "#how to use the test data, if the original train data already reduced?\n",
        "knn_model.score(embedding,y)\n",
        "#0.9542809642560266 - not as expected - FAILED"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}